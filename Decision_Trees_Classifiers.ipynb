{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pydot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_labels = pd.read_csv(\"logs_labels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expression-based feature extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = []\n",
    "method = []\n",
    "login = []\n",
    "status = []\n",
    "request_len = []\n",
    "bytes_sent = []\n",
    "\n",
    "\n",
    "for i in range(len(logs_labels.full_log)):\n",
    "    \n",
    "    r = re.compile(r\"^\\[([\\w:/]+\\s[+\\-]\\d{4})\\] (\\S+)\\s?(\\S+)?\\s?(\\S+)? (\\d{3}|-) (\\d+|-)\")\n",
    "    result = r.findall(logs_labels.full_log[i])\n",
    "    timestamp.append(result[0][0])\n",
    "    method.append(result[0][1])\n",
    "    if \"login\" in result[0][2]:\n",
    "        login.append(1)\n",
    "    elif \"admin\" in result[0][2]:\n",
    "        login.append(1)\n",
    "    else: \n",
    "        login.append(0)\n",
    "    status.append((result[0][4]))\n",
    "    request_len.append(len(result[0][2]))\n",
    "    bytes_sent.append(result[0][5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary and full label extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binary = [0 if i == 0 else 1 for i in logs_labels.label]\n",
    "\n",
    "label_full = []\n",
    "for i in logs_labels.label:\n",
    "    if i == 0:\n",
    "        label_full.append(0)\n",
    "    elif i == 10:\n",
    "        label_full.append(10)\n",
    "    else:\n",
    "        label_full.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 199890, 1: 27329, 10: 620})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(label_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate, one-hot encode and split data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(input_list):\n",
    "    output = np.zeros((len(input_list), len(set(input_list))))\n",
    "    index = {v: k for k, v in enumerate(sorted(set(input_list)))}\n",
    "    for i in range(len(input_list)):\n",
    "        output[i,index[input_list[i]]] = 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_discrete = np.vstack((np.array(login), np.array(request_len), np.array(bytes_sent)))\n",
    "data_categorical = np.concatenate((one_hot(method), one_hot(status)), axis = 1)\n",
    "data = np.concatenate((data_discrete.T, data_categorical), axis = 1)\n",
    "\n",
    "column_names = [\"login\", \"request_len\", \"bytes_sent\"]\n",
    "column_names += list((sorted(set(method))))\n",
    "column_names += list((sorted(set(status))))\n",
    "\n",
    "X = pd.DataFrame(data, columns = column_names)\n",
    "test_split = int(.75*len(logs_labels.full_log))\n",
    "data_train = X[:test_split]\n",
    "label_train = label_binary[:test_split]\n",
    "X_test = X[test_split:]\n",
    "y_test = label_binary[test_split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: login\n",
      "2: request_len\n",
      "3: bytes_sent\n",
      "4: DEBUG\n",
      "5: GET\n",
      "6: HEAD\n",
      "7: INDEX\n",
      "8: OPTIONS\n",
      "9: POST\n",
      "10: PUT\n",
      "11: SEARCH\n",
      "12: TRACE\n",
      "13: ZIZYKAFG\n",
      "14: 200\n",
      "15: 301\n",
      "16: 302\n",
      "17: 304\n",
      "18: 400\n",
      "19: 403\n",
      "20: 404\n",
      "21: 405\n",
      "22: 429\n",
      "23: 499\n",
      "24: 500\n",
      "25: 504\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(column_names):\n",
    "    print(str(i +1)+ \":\",j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up and train Decision Tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data_train, label_train, test_size=0.25, random_state=2809)\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth = 5)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate and evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set evaluation:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00     38145\n",
      "          1       0.94      0.98      0.96      4575\n",
      "\n",
      "avg / total       0.99      0.99      0.99     42720\n",
      "\n",
      "Test set evaluation:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00     47679\n",
      "          1       0.97      0.99      0.98      9281\n",
      "\n",
      "avg / total       0.99      0.99      0.99     56960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation set evaluation:\")\n",
    "y_pred = model.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "print(\"Test set evaluation:\")\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export tree visualisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export_graphviz(model, feature_names=column_names, filled=True, rounded=True)\n",
    "\n",
    "#(graph,) = pydot.graph_from_dot_file('tree.dot')\n",
    "#graph.write_png('tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of escalated log entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load extra packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load IP data and split as previously configured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = pd.read_csv(\"ips_sorted.txt\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_train = ip[:test_split]\n",
    "ip_test = ip[test_split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timestamps in original data have recurring instances, multiple entries on the same second. Append extra milliseconds to have unique timestamp for each entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "times_appended_ms = []\n",
    "\n",
    "for i in range(len(timestamp)):\n",
    "    time = timestamp[i]\n",
    "    time = time.replace(\" +0200\", \"\")\n",
    "    time = datetime.strptime(time, \"%d/%b/%Y:%H:%M:%S\")\n",
    "    times.append(time)\n",
    "    if i == 0:\n",
    "        times_appended_ms.append(time)\n",
    "    else:\n",
    "        if time == times[i-1]:\n",
    "            time = times_appended_ms[i-1]\n",
    "            times_appended_ms.append(time + timedelta(milliseconds=4))\n",
    "        else:\n",
    "            times_appended_ms.append(time)\n",
    "\n",
    "real_times = times_appended_ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new dataframe, concatenating IP and whether or not this entry is classified in X0 or X1. Timestamps are the new index, to allow for time-based computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_data = pd.concat([ip, pd.DataFrame(label_binary)], axis = 1)\n",
    "ip_data.columns = [\"ip\", \"classification\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_data = pd.concat([ip_data, pd.DataFrame(data)], axis = 1)\n",
    "ip_data.index = pd.to_datetime(real_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column classification is summed with a rolling window of 5 minutes. So, if an IP is classified in X1 10 times in the preceding 5 minutes, the result of the following calculation for that entry is 10. This can be done with a single line of code, using Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_data[\"classification\"] = ip_data[\"classification\"].groupby(ip_data[\"ip\"], group_keys=False).rolling('300s').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timestamps are no longer required, so reset the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the IP column, since it was only used as an identifier for the previous calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = ip_data.drop(\"ip\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split full IP data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_data_train = training_data[:test_split]\n",
    "ip_label_train = label_full[:test_split]\n",
    "ip_data_test = training_data[test_split:]\n",
    "ip_label_test = label_full[test_split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and validation sets, fit model, and evaluate validation set. Model performance seems low, because it is hard for the model to predict label 10 on the exact right log entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     38145\n",
      "          1       0.97      0.81      0.88      4433\n",
      "         10       0.07      0.45      0.12       142\n",
      "\n",
      "avg / total       0.99      0.98      0.98     42720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(ip_data_train, ip_label_train, test_size=0.25, random_state=2809)\n",
    "    \n",
    "model = DecisionTreeClassifier(criterion =\"entropy\", max_depth = 25, max_features = .67, class_weight = \"balanced\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discovery rate calculations on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(ip_data_test)\n",
    "ip_and_label = pd.DataFrame({\"y_val\": ip_label_test, \"y_pred\": y_pred_test, \"ip\": list(ip_test[0])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_and_true_label_10 = ip_and_label.loc[(ip_and_label[\"y_val\"] == 10)]\n",
    "ip_and_pred_label_10 = ip_and_label.loc[(ip_and_label[\"y_pred\"] == 10)]\n",
    "ip_true = set(ip_and_true_label_10.ip)\n",
    "ip_pred = set(ip_and_pred_label_10.ip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate and print discovery rate. Getting discovery rate on the test set, so performance is lower than on the full dataset, which is what is reported in the thesis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "disc_ip = 0\n",
    "for i in ip_pred:\n",
    "    if i in ip_true:\n",
    "        disc_ip += 1\n",
    "        \n",
    "print (disc_ip/len(ip_true))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
